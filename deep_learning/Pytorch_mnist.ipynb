{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddharth1608/datascience/blob/master/Pytorch_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "9epgFhgZOfvT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Handwritten Digit Classifier using CNN in Pytorch ##"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "90862490-49ae-4060-c3b4-30face6172d8",
        "id": "7yn8YWlrCQBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fsGGRLvjOjEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqLE41u8Q4XW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_dataset = pd.read_csv('/content/sample_data/mnist_train_small.csv', header=None)\n",
        "test_dataset = pd.read_csv('/content/sample_data/mnist_test.csv', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ht4pebaYRtNu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3c13b73-4dd6-490a-a8e4-318e25df0964"
      },
      "cell_type": "code",
      "source": [
        "print('Train shape {}, Test shape {}'.format(train_dataset.shape, test_dataset.shape))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape (20000, 785), Test shape (10000, 785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j4Y9PaEIkrbP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The dataset has first column as the label. and image data as flattened, 784 cells - we need to make it in grid shape of size 28 x 28"
      ]
    },
    {
      "metadata": {
        "id": "enn6jEeD1tGi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to load our custom dataset into Pytorch and use DataLoader we have to inherit torch.DataSet class"
      ]
    },
    {
      "metadata": {
        "id": "TPGn6rUEmoXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomMNISTDatasetFromCSV(Dataset):\n",
        "  def __init__(self, file_path, image_height, image_width, transforms=None):\n",
        "    self.data = pd.read_csv(file_path, header=None)\n",
        "    self.labels = self.data.iloc[:,0]\n",
        "    self.image_height = image_height\n",
        "    self.image_width = image_width\n",
        "    self.transforms = transforms\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    image_label = self.labels[index]\n",
        "    image_as_np_arr = np.asarray(self.data.iloc[index][1:]).reshape(self.image_height, self.image_width).astype('uint8')\n",
        "    # uint8 - unsigned int, 0-255\n",
        "    \n",
        "    if self.transforms is not None:\n",
        "        img_as_tensor = self.transforms(image_as_np_arr)\n",
        "        \n",
        "    return (img_as_tensor, image_label)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.data.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IPSfbwskvfPP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define transforms\n",
        "transformations = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Define custom dataset\n",
        "train_mnist_from_csv = CustomMNISTDatasetFromCSV('/content/sample_data/mnist_train_small.csv',28, 28,\n",
        "                         transformations)\n",
        "\n",
        "test_mnist_from_csv = CustomMNISTDatasetFromCSV('/content/sample_data/mnist_test.csv',28, 28,\n",
        "                         transformations)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_mnist_from_csv, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_mnist_from_csv, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-9ByYoVK5Jg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we will create the Layers for our Convolutional Neural network"
      ]
    },
    {
      "metadata": {
        "id": "KmfT-_FBLCV6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN,self).__init__();\n",
        "    \n",
        "    # Our first layer would consists of \n",
        "    # 1. Convolution Layer: 32 filters/channels of size 5x5 and stride of 1(slide unit)\n",
        "    # 2. Relu Layer\n",
        "    # 3. Pooling Layer\n",
        "    \n",
        "    self.layer1 = nn.Sequential(\n",
        "                      nn.Conv2d(1, 32, kernel_size=5, stride = 1, padding =2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "                  )\n",
        "    \n",
        "    # Our second layer would consist of similar structure except that input will be 32 channels and output will be \n",
        "    # 64 channels\n",
        "    self.layer2 = nn.Sequential(\n",
        "                      nn.Conv2d(32, 64, kernel_size = 5, stride = 1, padding = 2),\n",
        "                      nn.ReLU(),\n",
        "                      nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "                  )\n",
        "    \n",
        "    self.dropout = nn.Dropout()\n",
        "    \n",
        "    # Fully connected Layer network to flatten the channels - '7 * 7'(image size) * 64(no of channels)\n",
        "    self.fc1 = nn.Linear(7*7*64, 1000)\n",
        "    \n",
        "    # Last layer to assign values to labels, 0-9\n",
        "    self.fc2 = nn.Linear(1000, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "\n",
        "    # Below we Reshape the layer2 output with Number of rows and unknown columns. This will flatten the 7 * 7 images of every 64 channels\n",
        "    out = out.reshape(out.shape[0],-1) \n",
        "\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "le3AINCQbxs1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**How is the padding decided ?**\n",
        "\n",
        "${W_{out} = {\\frac{W_{in}-F + 2P}{S}} + 1  }$\n",
        "\n",
        "${W_{out} } $ is the dimension of output after convolution\n",
        "\n",
        "${ W_{in} } $ is the dimension of the input. \n",
        "\n",
        "${F}$ : Filter size\n",
        "\n",
        "${S }$: Stride\n",
        "\n",
        "${P}$: Padding\n",
        "\n",
        "We want to apply a filter 5 x5 and with a stride of 1. Also we want the input and output of same dimensions so we plug in these values in the above formula which suggests us to use Padding of 2.\n",
        "\n",
        "The same formula can be used to find padding for Pooling operation. We want to down sample the images from 28 \\* 28 to 14 \\* 14, which can be achieved by using a padding of 0"
      ]
    },
    {
      "metadata": {
        "id": "_SKhlsdhOI3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Model Training**"
      ]
    },
    {
      "metadata": {
        "id": "FqEHkydsN0IV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "cf085625-dc22-4bd2-a6e2-d99a98c1a15f"
      },
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Run the forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # Backprop and perform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list.append(correct / total)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
        "                          (correct / total) * 100))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/200], Loss: 0.1386, Accuracy: 93.00%\n",
            "Epoch [1/5], Step [200/200], Loss: 0.1327, Accuracy: 97.00%\n",
            "Epoch [2/5], Step [100/200], Loss: 0.0497, Accuracy: 99.00%\n",
            "Epoch [2/5], Step [200/200], Loss: 0.0406, Accuracy: 98.00%\n",
            "Epoch [3/5], Step [100/200], Loss: 0.0782, Accuracy: 99.00%\n",
            "Epoch [3/5], Step [200/200], Loss: 0.0466, Accuracy: 98.00%\n",
            "Epoch [4/5], Step [100/200], Loss: 0.0116, Accuracy: 100.00%\n",
            "Epoch [4/5], Step [200/200], Loss: 0.0455, Accuracy: 99.00%\n",
            "Epoch [5/5], Step [100/200], Loss: 0.0124, Accuracy: 100.00%\n",
            "Epoch [5/5], Step [200/200], Loss: 0.1364, Accuracy: 96.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bLmam62t1irs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Test the model**"
      ]
    },
    {
      "metadata": {
        "id": "Jp7XrH_X1k8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "833486a4-5210-465c-e103-b7f9108d7a54"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 97.92 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}