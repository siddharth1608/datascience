{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing - Encode, Normalize features ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n",
    "def generate_dummies(df, columns, prefixes=\"\"):\n",
    "    \n",
    "    if len(columns)>0:\n",
    "        assert ((len(prefixes)>0)), \\\n",
    "               \"Prefixes must be mentioned for all dummies columns\"\n",
    "    \n",
    "    index = 0\n",
    "    for col in tqdm(columns):\n",
    "        if len(prefixes)>0:\n",
    "            temp = pd.get_dummies(df[col],prefix=prefixes[index])\n",
    "        else:\n",
    "            temp = pd.get_dummies(df[col])       \n",
    "        df = pd.concat([df, temp], axis=1)\n",
    "        index = index + 1\n",
    "    return df    \n",
    "\n",
    "def label_encode(values):\n",
    "    # Label Encoding Categorical columns\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    values = [ element if type(element) is str else '' for element in values]\n",
    "    le.fit(values)        \n",
    "    return le.transform(values)\n",
    "\n",
    "def label_decode(values, value_to_decode):\n",
    "    # Label Encoding Categorical columns\n",
    "    le = preprocessing.LabelEncoder()    \n",
    "    values = [ element if type(element) is str else '' for element in values]\n",
    "    le.fit(values)\n",
    "    return le.inverse_transform(value_to_decode)\n",
    "\n",
    "def normalize(values):\n",
    "    #Normalize using StandardScaler, setting Mean zero and Variance 1\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(values)\n",
    "    return scaler.fit_transform(df[col])\n",
    "    \n",
    "    \n",
    "def preprocess(df, columns, dummies_cols = \"\", dummies_cols_prefix = \"\"):\n",
    "    for col in tqdm(columns):\n",
    "        \n",
    "        # Processing for String columns\n",
    "        if df[col].dtype == object: #For String columns\n",
    "            \n",
    "            # Replace NAs with ''\n",
    "            df[col] = df[col].fillna('')\n",
    "            \n",
    "            # Label Encoding Categorical columns \n",
    "            df[col] = label_encode(df[col])\n",
    "        \n",
    "        # Processing for Numeric columns\n",
    "        if (df[col].dtype == int) | (df[col].dtype == float):\n",
    "                        \n",
    "            df[col] = normalize(df[col])    \n",
    "        \n",
    "    \n",
    "    if len(dummies_cols)>0:\n",
    "            df = generate_dummies(df, dummies_cols, dummies_cols_prefix)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def traintestsplit(df, features_cols, target_col, test_perc = 0.2):\n",
    "    return model_selection.train_test_split(df[features_cols], df[target_col], \\\n",
    "                                            test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Features ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_cols = ['COLNAME1','COLNAME2']\n",
    "dummies_cols_prefix = dummies_cols\n",
    "\n",
    "# List to contain names of dummies column generated with prefix\n",
    "dummies_cols_prefixed = []\n",
    "            \n",
    "for index in range(0,len(dummies_cols)):\n",
    "    for value in candidates_procsd_df[dummies_cols[index]].unique():\n",
    "        dummies_cols_prefixed.append(dummies_cols_prefix[index] + '_' + value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use dummies_cols_prefixed when passing all the dummy columns in the model**\n",
    "\n",
    "*For example:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procsd_df = preprocess(df, \\\n",
    "                      columns=features_cols, \\\n",
    "                      dummies_cols=dummies_cols, \\\n",
    "                      dummies_cols_prefix=dummies_cols_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_values_and_extract_column_names(df, source_col, delimiter = \";\", prefix = source_col):\n",
    "    column_values = []\n",
    "    for value in df[source_col].unique():\n",
    "        tmp_list = []\n",
    "        value = str.strip(value)\n",
    "        if value != '':\n",
    "            tmp_list = value.split(';')\n",
    "        column_values = column_values + tmp_list\n",
    "\n",
    "    column_values = set(column_values)\n",
    "\n",
    "    column_values_colnames = [prefix + str.upper(value) for value in column_values]\n",
    "    \n",
    "    return column_values_colnames\n",
    "    \n",
    "def add_empty_cols_to_df(df, column_names):   \n",
    "    return pd.concat([df,pd.DataFrame(columns=column_names)], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
